<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Jonathan Sarker</title>
<link>http://thenewexecutor.github.io/projects.html</link>
<atom:link href="http://thenewexecutor.github.io/projects.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.4.550</generator>
<lastBuildDate>Tue, 04 Jun 2024 00:00:00 GMT</lastBuildDate>
<item>
  <title>Self Learning Journey</title>
  <link>http://thenewexecutor.github.io/projects/library/</link>
  <description><![CDATA[ 




<p><br></p>
<section id="motivation" class="level1">
<h1>Motivation</h1>
<p>What is the extent of a person’s knowledge? Teaching is gold proof of mastery, but outside of that, we often rely on proxies. In the job application process, a person’s educational background, work history or performance on a coding test are common ones. One personal favorite of mine is looking at someone’s bookshelf as it can potentially be a glimpse into the contents of their mind. As a huge fan of self-learning, I’ve done my fair share. I started with local library books on dinosaurs, continued on with gems like <em>The Feynman Lectures on Physics</em> in college and <em>Principles of Quantum Mechanics</em> in graduate school.</p>
<p>After graduate school, I dedicated myself to becoming a data scientist by first studying fundamentals, including graduate level statistics and Python/machine learning related online courses. This habit of self-study took great discipline to develop and I’m proud of all the work I’ve put in and continue to put in, yet there’s not enough room for it on a resume. The content of this page is an attempt at some documentation of my self-learning journey and what you’d see on my personal bookshelf.<br>
<br></p>
</section>
<section id="whats-on-my-shelf" class="level1">
<h1>What’s on my shelf?</h1>
<section id="physics" class="level2">
<h2 class="anchored" data-anchor-id="physics">Physics</h2>
<ul>
<li><a href="https://www.feynmanlectures.caltech.edu/index.html">The Feynman Lectures on Physics</a> by Richard Feynman
<ul>
<li>These volumes have a wealth of insight and beautiful exposition straight from one of greatest teachers and legends of the subject. What other physics text has the Krebs Cycle?</li>
</ul></li>
<li><a href="https://www.amazon.com/Principles-Quantum-Mechanics-2nd-Shankar/dp/0306447908/ref=asc_df_0306447908?mcid=9ac2bf11d48e36a7a5fb25f3a3845ea3&amp;hvocijid=6271115953609912194-0306447908-&amp;hvexpln=73&amp;tag=hyprod-20&amp;linkCode=df0&amp;hvadid=721245378154&amp;hvpos=&amp;hvnetw=g&amp;hvrand=6271115953609912194&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9191415&amp;hvtargid=pla-2281435179538&amp;psc=1">Principles of Quantum Mechanics</a> by Ramamurti Shankar
<ul>
<li>With solved problems, fantastic organization and such a strong 1st chapter, this text helped me learn quantum mechanics more than any of the numerous classes I’ve taken.</li>
</ul></li>
</ul>
</section>
<section id="mathematics" class="level2">
<h2 class="anchored" data-anchor-id="mathematics">Mathematics</h2>
<ul>
<li><a href="https://www.amazon.com/How-Prove-Structured-Daniel-Velleman/dp/110842418X/ref=asc_df_110842418X?mcid=5af9469a059e313b9ba60a74ff76f0aa&amp;hvocijid=15755551501711694689-110842418X-&amp;hvexpln=73&amp;tag=hyprod-20&amp;linkCode=df0&amp;hvadid=721245378154&amp;hvpos=&amp;hvnetw=g&amp;hvrand=15755551501711694689&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9191415&amp;hvtargid=pla-2281435178098&amp;psc=1">How to Prove It</a> by Daniel J. Velleman
<ul>
<li>I recall stumbling through proofs before working through the first few chapters of this helpful resource.</li>
</ul></li>
<li><a href="https://www.amazon.com/All-Statistics-Statistical-Inference-Springer/dp/1441923225">All of Statistics</a> by Larry Wasserman
<ul>
<li>This book has such a high range of topics and working through through many of the problems yielded long-lasting insights into graduate statistics.</li>
</ul></li>
<li><a href="https://www.amazon.com/Statistical-Inference-George-Casella/dp/0534243126">Statistical Inference</a> by George Casella and Roger Berger
<ul>
<li>This is a staple reference whenever I find myself requiring deeper insight into fundamentals.</li>
</ul></li>
</ul>
</section>
<section id="machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning">Machine Learning</h2>
<ul>
<li><a href="https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981">Information Theory, Inference and Learning Algorithms</a> by David MacKay
<ul>
<li>Another amazing resource for self-study, providing insightful expositions and exercises with Bayesian inference, core information theory like entropy and machine learning’s relation to compression.</li>
</ul></li>
<li><a href="https://www.statlearning.com/">Introduction to Statistical Learning</a> by Hastie, Tibshirani, James and Witten
<ul>
<li>This book has some nice explanations of decision trees and is accessible.</li>
</ul></li>
<li><a href="https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576">The Elements of Statistical Learning</a> by Hastie, Tibshirani and Friedman
<ul>
<li>A well known resource and great reference for insights into machine learning.</li>
</ul></li>
<li><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai &amp; PyTorch</a> by Jeremy Howard and Sylvain Gugger
<ul>
<li>This book had such practical bits of knowledge and insights into Pytorch and applied machine learning, by one of the greatest contributors to the machine learning community.</li>
</ul></li>
<li><a href="https://www.amazon.com/Natural-Language-Processing-Transformers-Revised/dp/1098136799#">Natural Language Processing with Transformers</a> by Tunstall, von Werra and Wolf
<ul>
<li>Another great practical book by contributors to the machine learning community, providing insight into the transformers architecture and library.</li>
</ul></li>
<li><a href="https://www.amazon.com/Effective-XGBoost-Optimizing-Understanding-Classification/dp/1792310390">Effective Xgboost</a> by Matt Harrison
<ul>
<li>A practical guide to XGBoost and integration into workflows.</li>
</ul></li>
<li><a href="https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969">Designing Machine Learning Systems</a> by Chip Huyen
<ul>
<li>This was such a great book that helped me understand the bigger picture with machine learning, in the context of system design and MLops.</li>
</ul></li>
<li><a href="https://www.amazon.com/Effective-Data-Science-Infrastructure-scientists/dp/1617299197">Effective Data Science Infrastructure</a> by Ville Tuulos Written by the author of the library Metaflow, this provides great insights into productive workflows in data science and expressing that in code.</li>
<li><a href="https://www.amazon.com/Machine-Learning-PyTorch-Scikit-Learn-learning-ebook/dp/B09NW48MR1">Machine Learning with PyTorch and Scikit-Learn</a> by Sebastian Raschka
<ul>
<li>This book has a nice blend of fundamentals with application, signature to the author’s insightful writings and work in general.</li>
</ul></li>
<li><a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321">Designing Data-Intensive Applications</a> by Martin Kleppmann
<ul>
<li>A great reference for studying system design.</li>
</ul></li>
<li><a href="https://www.amazon.com/Data-Analysis-Machine-Learning-Kaggle/dp/1801817472">The Kaggle Book</a> by Banachewicz and Massaron
<ul>
<li>Filled with insights and tips in data science gleaned from Kaggle competitions.</li>
</ul></li>
<li><a href="https://www.amazon.com/Kaggle-Workbook-Self-learning-exercises-competitions/dp/1804611212">The Kaggle Workbook</a> by Banachewicz and Massaron
<ul>
<li>The practical counterpart to the previous book that helps build skill via code exercises.</li>
</ul></li>
</ul>
</section>
<section id="computer-science" class="level2">
<h2 class="anchored" data-anchor-id="computer-science">Computer Science</h2>
<ul>
<li>Introduction to Algorithms</li>
<li>The Algorithm Design Manual</li>
<li>Algorithm Design</li>
</ul>
</section>
<section id="programming" class="level2">
<h2 class="anchored" data-anchor-id="programming">Programming</h2>
<ul>
<li>Elements of Programming Interviews in Python</li>
<li>Effective Pandas</li>
<li>Architecture Patterns with Python</li>
<li>Mastering Regular Expressions</li>
<li>Software Engineering at Google</li>
</ul>
</section>
<section id="economics" class="level2">
<h2 class="anchored" data-anchor-id="economics">Economics</h2>
<ul>
<li>Basic Economics</li>
<li>Healthcare Issues: An Economic Perspective</li>
</ul>
</section>
<section id="productivity" class="level2">
<h2 class="anchored" data-anchor-id="productivity">Productivity</h2>
<ul>
<li>The 7 Habits of Highly Effective People</li>
<li>Atomic Habits</li>
<li>So Good They Can’t Ignore You</li>
<li>Deep Work</li>
<li>Slow Productivity</li>
<li>Range: Why Generalists Triumph in a Specialized World</li>
<li>Grit</li>
<li>The Startup of You</li>
<li>Zero to One</li>
</ul>
</section>
<section id="career-guides" class="level2">
<h2 class="anchored" data-anchor-id="career-guides">Career Guides</h2>
<ul>
<li>The Effective Engineer</li>
<li>Engineer’s Survival Guide</li>
<li>The Staff Engineer’s Path</li>
<li>The Software Engineer’s Guidebook</li>
</ul>


</section>
</section>

 ]]></description>
  <category>learning</category>
  <guid>http://thenewexecutor.github.io/projects/library/</guid>
  <pubDate>Tue, 04 Jun 2024 00:00:00 GMT</pubDate>
  <media:content url="http://thenewexecutor.github.io/projects/library/brain.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
